{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n_sample):\n",
    "    e = np.random.normal(loc=0, scale=1.0, size=[n_sample, 1])\n",
    "    gamma = np.random.normal(loc=0, scale=0.1, size=[n_sample, 1])\n",
    "    delta = np.random.normal(loc=0, scale=0.1, size=[n_sample, 1])\n",
    "\n",
    "    z = np.random.uniform(low=-3, high=3, size=[n_sample, 1])\n",
    "    t = np.reshape(z[:, 0], [-1, 1]) + e + gamma\n",
    "    y = np.abs(t) + e + delta\n",
    "    return {'t': t, 'y': y, 'z': z}\n",
    "\n",
    "train_data = generate_data(n_sample=100)\n",
    "validation_data = generate_data(n_sample=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a PyTorch model $f$ and a moment function $\\psi$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(1, 20),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(20, 3),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(3, 1)\n",
    "        )\n",
    "\n",
    "def moment_function(model_evaluation, y):\n",
    "    return model_evaluation - y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model using Kernel/Neural-FGEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running:  divergence=chi2, reg_param=0.1\n",
      "Running:  divergence=chi2, reg_param=0.01\n",
      "Running:  divergence=chi2, reg_param=0.001\n",
      "Running:  divergence=chi2, reg_param=0.0001\n",
      "Running:  divergence=chi2, reg_param=1e-06\n",
      "Running:  divergence=chi2, reg_param=1e-08\n",
      "Running:  divergence=kl, reg_param=0.1\n",
      "Running:  divergence=kl, reg_param=0.01\n",
      "Running:  divergence=kl, reg_param=0.001\n",
      "Running:  divergence=kl, reg_param=0.0001\n",
      "Running:  divergence=kl, reg_param=1e-06\n",
      "Running:  divergence=kl, reg_param=1e-08\n",
      "Running:  divergence=log, reg_param=0.1\n",
      "Running:  divergence=log, reg_param=0.01\n",
      "Running:  divergence=log, reg_param=0.001\n",
      "Running:  divergence=log, reg_param=0.0001\n",
      "Running:  divergence=log, reg_param=1e-06\n",
      "Running:  divergence=log, reg_param=1e-08\n",
      "Best config:  {'divergence': 'kl', 'reg_param': 1e-08}\n"
     ]
    }
   ],
   "source": [
    "from fgel.estimation import fgel_estimation\n",
    "\n",
    "trained_model, other_stats = fgel_estimation(model=model,           # Use any PyTorch model\n",
    "                                             train_data=train_data,\n",
    "                                             moment_function=moment_function,\n",
    "                                             version='kernel',     # 'kernel' or 'neural'\n",
    "                                             divergence=None,    # If 'None' optimize as hyperparam, otherise choose from ['chi2', 'kl', 'log']\n",
    "                                             reg_param=None,       # If 'None' optimize as hyperparam\n",
    "                                             validation_data=validation_data, \n",
    "                                             val_loss_func=None,   # Hand over custom validation loss with arguments (model, validation_data)\n",
    "                                             verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from fgel.estimation import fgel_estimation\n",
    "\n",
    "\n",
    "# Generate some data\n",
    "def generate_data(n_sample):\n",
    "    e = np.random.normal(loc=0, scale=1.0, size=[n_sample, 1])\n",
    "    gamma = np.random.normal(loc=0, scale=0.1, size=[n_sample, 1])\n",
    "    delta = np.random.normal(loc=0, scale=0.1, size=[n_sample, 1])\n",
    "\n",
    "    z = np.random.uniform(low=-3, high=3, size=[n_sample, 1])\n",
    "    t = np.reshape(z[:, 0], [-1, 1]) + e + gamma\n",
    "    y = np.abs(t) + e + delta\n",
    "    return {'t': t, 'y': y, 'z': z}\n",
    "\n",
    "train_data = generate_data(n_sample=100)\n",
    "validation_data = generate_data(n_sample=100)\n",
    "\n",
    "\n",
    "# Define a PyTorch model $f$ and a moment function $\\psi$\n",
    "model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(1, 20),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(20, 3),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(3, 1)\n",
    "        )\n",
    "\n",
    "def moment_function(model_evaluation, y):\n",
    "    return model_evaluation - y\n",
    "\n",
    "# Train the model using Kernel/Neural-FGEL\n",
    "trained_model, other_stats = fgel_estimation(model=model,           # Use any PyTorch model\n",
    "                                             train_data=train_data,\n",
    "                                             moment_function=moment_function,\n",
    "                                             version='kernel',     # 'kernel' or 'neural'\n",
    "                                             divergence=None,    # If 'None' optimize as hyperparam, otherise choose from ['chi2', 'kl', 'log']\n",
    "                                             reg_param=None,       # If 'None' optimize as hyperparam\n",
    "                                             validation_data=validation_data, \n",
    "                                             val_loss_func=None,   # Hand over custom validation loss with arguments (model, validation_data)\n",
    "                                             verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (rgmm)",
   "language": "python",
   "name": "rgmm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
